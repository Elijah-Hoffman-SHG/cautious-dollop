{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #of users added/updated\n",
    "\n",
    "Can pull this from pagelog dump or activity file\n",
    "\n",
    "Both files are huge\n",
    "\n",
    "Would probably lean toward activity file so we don't have to recreate filtering logic\n",
    "\n",
    "biq_query_activity.parquet in \\\\sandhills.int\\systems\\devFramework\\Machine_Learning\\spark_data\\recsys_files\\daily_refresh\n",
    "\n",
    "New user if min(click_datetime) is less than a day old\n",
    "\n",
    "Updated user otherwise\n",
    "\n",
    "Alternative would be Neo4j (probably preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #of listings added/updated\n",
    "\n",
    "Use the csv files in \\\\sandhills.int\\systems\\devFramework\\Machine_Learning\\spark_data\\dbd_files\\live\\active_listings\n",
    "\n",
    "Filter to listings created on or modified on within the last day\n",
    "\n",
    "Alternative would be Neo4j (still probably lean active listings files though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import os\n",
    "def get_new_stuff(path, filename):\n",
    "    file_path = os.path.join(path, filename)\n",
    "    filter_date = (dt.datetime.now(pytz.timezone('UTC')) - dt.timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    item_df = pd.read_csv(file_path, iterator=True, chunksize=1000)\n",
    "    df = pd.concat([chunk[(chunk['ListingCreatedOnUTCDateTime'] > filter_date)|(chunk['ListingModifiedOnUTCDateTime']>filter_date)] for chunk in item_df])\n",
    "    # item_df['ListingCreatedOnUTCDateTime'] = pd.to_datetime(item_df['ListingCreatedOnUTCDateTime'])\n",
    "    # item_df['ListingModifiedOnUTCDateTime'] = pd.to_datetime(item_df['ListingModifiedOnUTCDateTime'])\n",
    "    # item_df = item_df[(item_df['ListingCreatedOnUTCDateTime'] > filter_date) | (item_df['ListingModifiedOnUTCDateTime'] > filter_date)]\n",
    "    return df.shape[0]\n",
    "env = 'live'\n",
    "active_listing_path = f'/mnt/Machine_Learning/spark_data/dbd_files/{env}/active_listings'\n",
    "retail_name = 'ActiveRetailListing.csv'\n",
    "auction_name = 'ATEFActiveListings.csv'\n",
    "retail = get_new_stuff(active_listing_path,retail_name)\n",
    "auction = get_new_stuff(active_listing_path, auction_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #of active listings in Qdrant\n",
    "\n",
    "Use qdrant client to count points in the user collection\n",
    "\n",
    "https://qdrant.tech/documentation/concepts/points/#counting-points \n",
    "\n",
    "http://siml4:9217/dashboard#/collections/live_recsys_activity\n",
    "\n",
    "http://siml4:9217/dashboard#/collections/live_recsys_similar_items\n",
    "\n",
    "Can pull from active listings CSV dump, but prefer Qdrant here because some listings get filtered out due to API failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://siml4:9217/collections/dev_recsys_activity/points/count \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://wiml4:9217/collections/dev_recsys_activity/points/count \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://siml4:9217/collections/dev_recsys_similar_items/points/count \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://wiml4:9217/collections/dev_recsys_similar_items/points/count \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://siml4:9217/collections/dev_recsys_user/points/count \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://wiml4:9217/collections/dev_recsys_user/points/count \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CountResult(count=2385), CountResult(count=2385)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "class LoaderBase():\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.lnk_hostname = 'siml4'  # SIML4\n",
    "        self.saw_hostname = 'wiml4'\n",
    "\n",
    "class QdrantLoad(LoaderBase):\n",
    "    def __init__(self, collection, all_check=True):\n",
    "        super().__init__()\n",
    "        self.port = 9217\n",
    "        self.clients = [\n",
    "            QdrantClient(self.lnk_hostname, port=self.port, timeout=100000),\n",
    "            QdrantClient(self.saw_hostname, port=self.port, timeout=100000)\n",
    "        ]\n",
    "        self.collection = collection\n",
    "        self.all_check = all_check\n",
    "    \n",
    "    def get_active_listings(self):\n",
    "        counts = []\n",
    "        for client in self.clients:\n",
    "            try:\n",
    "                count = client.count(\n",
    "                    collection_name=self.collection,\n",
    "                    exact=True,\n",
    "                )\n",
    "                counts.append(count)\n",
    "            except ValidationError as e:\n",
    "                print(f\"Validation error fetching collection from {client}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching collection from {client}: {e}\")\n",
    "        return counts\n",
    "\n",
    "\n",
    "env = 'dev'\n",
    "qdrant_activity = 'recsys_activity'\n",
    "qdrant_similar_items = 'recsys_similar_items'\n",
    "qdrant_activity = f'{env}_{qdrant_activity}'\n",
    "qdrant_similar_items = f'{env}_{qdrant_similar_items}'\n",
    "\n",
    "qdrant_users = 'recsys_user'\n",
    "qdrant_users = f'{env}_{qdrant_users}'\n",
    "\n",
    "QdrantLoad(qdrant_activity).get_active_listings()\n",
    "QdrantLoad(qdrant_similar_items).get_active_listings()\n",
    "QdrantLoad(qdrant_users).get_active_listings()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #of users from bid prediction\n",
    "Have to pull that from Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import pandas as pd\n",
    "class LoaderBase():\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.lnk_hostname = 'siml4'  # SIML4\n",
    "        self.saw_hostname = 'wiml4'\n",
    "class RedisLoad(LoaderBase):\n",
    "    def __init__(self, key_prefix):\n",
    "        super().__init__()\n",
    "        self.port = 9216\n",
    "        self.db = 0\n",
    "        self.key_prefix = key_prefix\n",
    "        self.conns = [\n",
    "            redis.Redis(host=self.lnk_hostname, port=self.port, db=self.db),\n",
    "            redis.Redis(host=self.saw_hostname, port=self.port, db=self.db)\n",
    "        ]\n",
    "    def get_count_pattern(self):\n",
    "        count1 = 0\n",
    "        for conn in self.conns:\n",
    "            count = 0\n",
    "            for key in conn.scan_iter(f\"{self.key_prefix}*\"):\n",
    "                count+=1\n",
    "            count1+=count\n",
    "        return count1\n",
    "    \n",
    "bid_pred_prefix = 'dev:bid'\n",
    "RedisLoad(bid_pred_prefix).get_count_pattern()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neo4j num of users added/updated and num of listings added/updated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 21, 1, 540000000, tzinfo=<UTC>) i.Id=231094033>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 21, 48, 560000000, tzinfo=<UTC>) i.Id=231094033>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 21, 48, 170000000, tzinfo=<UTC>) i.Id=231094033>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 27, 20, 6, 1, 277000000, tzinfo=<UTC>) i.Id=235879667>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 24, 17, 3, 10, 917000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 24, 17, 3, 11, 363000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 24, 17, 3, 10, 460000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 19, 3, 59, 40, 870000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 18, 14, 36, 51, 27000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 18, 3, 58, 27, 167000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 18, 3, 58, 26, 950000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 6, 28, 41, 703000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 6, 28, 41, 973000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 6, 29, 21, 120000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 9, 47, 30, 497000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 6, 29, 20, 930000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 9, 47, 25, 90000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 4, 173000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 0, 803000000, tzinfo=<UTC>) i.Id=235274767>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 31, 10, 110000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 30, 35, 190000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 32, 25, 127000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 32, 31, 623000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 31, 11, 220000000, tzinfo=<UTC>) i.Id=235316275>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 8, 7, 17, 11, 25, 150000000, tzinfo=<UTC>) i.Id=233632903>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 8, 7, 17, 11, 25, 987000000, tzinfo=<UTC>) i.Id=233632903>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 15, 57, 54, 950000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 21, 33, 21, 973000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 15, 58, 49, 927000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 15, 59, 13, 277000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 16, 2, 3, 963000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 15, 58, 14, 983000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 16, 0, 24, 597000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 16, 2, 4, 537000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 16, 0, 58, 473000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 16, 0, 0, 780000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 10, 16, 1, 23, 917000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 55, 503000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 22, 44, 14, 267000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 19, 887000000, tzinfo=<UTC>) i.Id=231468105>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 32, 983000000, tzinfo=<UTC>) i.Id=235641517>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 57, 860000000, tzinfo=<UTC>) i.Id=231219389>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 55, 190000000, tzinfo=<UTC>) i.Id=231219389>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 56, 267000000, tzinfo=<UTC>) i.Id=231219389>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 9, 20, 23, 58, 683000000, tzinfo=<UTC>) i.Id=231219389>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 7, 24, 13, 8, 4, 33000000, tzinfo=<UTC>) i.Id=235055555>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 8, 11, 16, 50, 37, 303000000, tzinfo=<UTC>) i.Id=229611021>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 8, 11, 15, 55, 17, 713000000, tzinfo=<UTC>) i.Id=234350817>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 8, 11, 15, 53, 57, 753000000, tzinfo=<UTC>) i.Id=231939341>, <Record r.CreatedAt=neo4j.time.DateTime(2024, 8, 11, 15, 45, 1, 880000000, tzinfo=<UTC>) i.Id=228360357>]\n",
      "                            r.CreatedAt       i.Id\n",
      "0   2024-07-09T20:21:01.540000000+00:00  231094033\n",
      "1   2024-07-09T20:21:48.560000000+00:00  231094033\n",
      "2   2024-07-09T20:21:48.170000000+00:00  231094033\n",
      "3   2024-07-27T20:06:01.277000000+00:00  235879667\n",
      "4   2024-07-24T17:03:10.917000000+00:00  235274767\n",
      "5   2024-07-24T17:03:11.363000000+00:00  235274767\n",
      "6   2024-07-24T17:03:10.460000000+00:00  235274767\n",
      "7   2024-07-19T03:59:40.870000000+00:00  235274767\n",
      "8   2024-07-18T14:36:51.027000000+00:00  235274767\n",
      "9   2024-07-18T03:58:27.167000000+00:00  235274767\n",
      "10  2024-07-18T03:58:26.950000000+00:00  235274767\n",
      "11  2024-07-10T06:28:41.703000000+00:00  235316275\n",
      "12  2024-07-10T06:28:41.973000000+00:00  235316275\n",
      "13  2024-07-10T06:29:21.120000000+00:00  235316275\n",
      "14  2024-07-10T09:47:30.497000000+00:00  235316275\n",
      "15  2024-07-10T06:29:20.930000000+00:00  235316275\n",
      "16  2024-07-10T09:47:25.090000000+00:00  235316275\n",
      "17  2024-07-09T20:23:04.173000000+00:00  235274767\n",
      "18  2024-07-09T20:23:00.803000000+00:00  235274767\n",
      "19  2024-07-09T20:31:10.110000000+00:00  235316275\n",
      "20  2024-07-09T20:30:35.190000000+00:00  235316275\n",
      "21  2024-07-09T20:32:25.127000000+00:00  235316275\n",
      "22  2024-07-09T20:32:31.623000000+00:00  235316275\n",
      "23  2024-07-09T20:31:11.220000000+00:00  235316275\n",
      "24  2024-08-07T17:11:25.150000000+00:00  233632903\n",
      "25  2024-08-07T17:11:25.987000000+00:00  233632903\n",
      "26  2024-07-10T15:57:54.950000000+00:00  231468105\n",
      "27  2024-07-10T21:33:21.973000000+00:00  231468105\n",
      "28  2024-07-10T15:58:49.927000000+00:00  231468105\n",
      "29  2024-07-10T15:59:13.277000000+00:00  231468105\n",
      "30  2024-07-10T16:02:03.963000000+00:00  231468105\n",
      "31  2024-07-10T15:58:14.983000000+00:00  231468105\n",
      "32  2024-07-10T16:00:24.597000000+00:00  231468105\n",
      "33  2024-07-10T16:02:04.537000000+00:00  231468105\n",
      "34  2024-07-10T16:00:58.473000000+00:00  231468105\n",
      "35  2024-07-10T16:00:00.780000000+00:00  231468105\n",
      "36  2024-07-10T16:01:23.917000000+00:00  231468105\n",
      "37  2024-07-09T20:23:55.503000000+00:00  231468105\n",
      "38  2024-07-09T22:44:14.267000000+00:00  231468105\n",
      "39  2024-07-09T20:23:19.887000000+00:00  231468105\n",
      "40  2024-07-09T20:23:32.983000000+00:00  235641517\n",
      "41  2024-07-09T20:23:57.860000000+00:00  231219389\n",
      "42  2024-07-09T20:23:55.190000000+00:00  231219389\n",
      "43  2024-07-09T20:23:56.267000000+00:00  231219389\n",
      "44  2024-07-09T20:23:58.683000000+00:00  231219389\n",
      "45  2024-07-24T13:08:04.033000000+00:00  235055555\n",
      "46  2024-08-11T16:50:37.303000000+00:00  229611021\n",
      "47  2024-08-11T15:55:17.713000000+00:00  234350817\n",
      "48  2024-08-11T15:53:57.753000000+00:00  231939341\n",
      "49  2024-08-11T15:45:01.880000000+00:00  228360357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from py_framework.bis.connectors import Neo4jConnector # type: ignore\n",
    "from py_framework.common.sandhills_config import Config\n",
    "\n",
    "\n",
    "lnk_connection = Config().get('con_neo4j_LNK', config_section='default')\n",
    "saw_connection = Config().get('con_neo4j_SAW', config_section='default')\n",
    "query = \"\"\"\n",
    "MATCH (p:User)-[r:CLICKED_ITEM]->(i:Item)\n",
    "WHERE r.CreatedAt\n",
    "LIMIT 50\n",
    "\"\"\"\n",
    "with Neo4jConnector([lnk_connection, saw_connection]) as neo4j:\n",
    "    ballin1 = neo4j.query(query)[0]\n",
    "    print(ballin1)\n",
    "    ballin = neo4j.structure_results(neo4j.query(query)[0])\n",
    "    print(ballin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending da emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_new_stuff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m retail_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActiveRetailListing.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m auction_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATEFActiveListings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m retail \u001b[38;5;241m=\u001b[39m \u001b[43mget_new_stuff\u001b[49m(active_listing_path,retail_name)\n\u001b[1;32m     15\u001b[0m auction \u001b[38;5;241m=\u001b[39m get_new_stuff(active_listing_path, auction_name)\n\u001b[1;32m     17\u001b[0m qdrant_activity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecsys_activity\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_new_stuff' is not defined"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "import smtplib\n",
    "import requests\n",
    "import json\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtp2go.core import Smtp2goClient\n",
    "bid_pred_prefix = 'dev:bid'\n",
    "env = 'dev'\n",
    "count_of_bid_pred_users = 0\n",
    "active_listing_path = f'/mnt/Machine_Learning/spark_data/dbd_files/{env}/active_listings'\n",
    "retail_name = 'ActiveRetailListing.csv'\n",
    "auction_name = 'ATEFActiveListings.csv'\n",
    "retail = get_new_stuff(active_listing_path,retail_name)\n",
    "auction = get_new_stuff(active_listing_path, auction_name)\n",
    "\n",
    "qdrant_activity = 'recsys_activity'\n",
    "qdrant_similar_items = 'recsys_similar_items'\n",
    "qdrant_activity = f'{env}_{qdrant_activity}'\n",
    "qdrant_similar_items = f'{env}_{qdrant_similar_items}'\n",
    "\n",
    "qdrant_users = 'recsys_user'\n",
    "qdrant_users = f'{env}_{qdrant_users}'\n",
    "\n",
    "activity_counts = QdrantLoad(qdrant_activity).get_active_listings()\n",
    "similar_items_counts = QdrantLoad(qdrant_similar_items).get_active_listings()\n",
    "user_counts = QdrantLoad(qdrant_users).get_active_listings()\n",
    "\n",
    "activity_count = sum(activity_counts)\n",
    "similar_items_count = sum(similar_items_counts)\n",
    "user_count = sum(user_counts)\n",
    "\n",
    "client = Smtp2goClient(api_key='api-F0A1307427B54E37AD279EE0814E9D2C')\n",
    "\n",
    "html_content = f\"\"\"\n",
    "<html>\n",
    "<body>\n",
    "    <h1>Listing Information</h1>\n",
    "    <table border=\"1\">\n",
    "        <tr>\n",
    "            <th>Category</th>\n",
    "            <th>Count</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Bid Pred Users</td>\n",
    "            <td>{count_of_bid_pred_users}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Retail Listings</td>\n",
    "            <td>{retail}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Auction Listings</td>\n",
    "            <td>{auction}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Activity Count</td>\n",
    "            <td>{activity_count}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Similar Items Count</td>\n",
    "            <td>{similar_items_count}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>User Count</td>\n",
    "            <td>{user_count}</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "payload = {\n",
    "   'sender': 'shithead-shi-thead@outlook.com',\n",
    "   'recipients': ['ehof17@gmail.com', 'elijah-hoffman@sandhills.com'],\n",
    "   'subject': 'Very tough here',\n",
    "   'text': 'Test Message',\n",
    "   'html': html_content,\n",
    "   'custom_headers': {'Your-Custom-Headers': 'Custom Values'}\n",
    "}\n",
    "\n",
    "resp = client.send(**payload)\n",
    "smtp2goPass = '$unnySands-ButDontTellMe'\n",
    "#Outlook stmp server\n",
    "port = 587\n",
    "smtp_server = \"smtp.office365.com\"\n",
    "login = \"elijah-hoffman@sandhills.com\"\n",
    "password = \"$unshineSANDHILLSBoy24\"\n",
    "\n",
    "receiver_email = \"elijah-hoffman@sandhills.com\"\n",
    "\n",
    "message = \"\"\"\\\n",
    "Subject: Hi there!\n",
    "\n",
    "\n",
    "Some people say life is easy. The problem with that is we live this life not because it is easy but because it is hard.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "\n",
    "\n",
    "msg = MIMEMultipart('mixed')\n",
    "\n",
    "sender = 'shithead-shi-thead@outlook.com'\n",
    "recipient = 'elijah-hoffman@sandhills.com'\n",
    "\n",
    "msg['Subject'] = 'Your Subject'\n",
    "msg['From'] = sender\n",
    "msg['To'] = recipient\n",
    "\n",
    "text_message = MIMEText('It is a text message.', 'plain')\n",
    "html_message = MIMEText('It is a html message.', 'html')\n",
    "msg.attach(text_message)\n",
    "msg.attach(html_message)\n",
    "\n",
    "mailServer = smtplib.SMTP('mail.smtp2go.com', 2525) #  8025, 587 and 25 can also be used. \n",
    "mailServer.ehlo()\n",
    "mailServer.starttls()\n",
    "mailServer.ehlo()\n",
    "mailServer.login(login, smtp2goPass)\n",
    "mailServer.sendmail(sender, recipient, msg.as_string())\n",
    "mailServer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min ± 549 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from fetchers import FileFetch, QdrantFetch, Neo4jFetch, RedisFetch\n",
    "swag = 'dev:bid'\n",
    "%timeit RedisFetch(swag).scan_iter_bench()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_data_prep-qIt49XRw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
